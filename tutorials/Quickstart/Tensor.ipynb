{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0211a5a-ebdb-419c-8dd1-79ebd1f4188a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T05:30:44.785549Z",
     "iopub.status.busy": "2024-12-11T05:30:44.784359Z",
     "iopub.status.idle": "2024-12-11T05:30:44.807483Z",
     "shell.execute_reply": "2024-12-11T05:30:44.806039Z",
     "shell.execute_reply.started": "2024-12-11T05:30:44.785462Z"
    }
   },
   "source": [
    "# Tensors\n",
    "1. 张量的定义：\n",
    "- 张量类似于NumPy 的 ndarray，但具备更多的功能。\n",
    "- 它是PyTorch 中的核心数据结构，用来表示数据和参数。\n",
    "2. 与 NumPy 的区别：\n",
    "- GPU 加速：张量可以在GPU 或其他硬件加速器上运行，这使得深度学习的计算更高效。\n",
    "- 内存共享：PyTorch 张量和 NumPy 数组可以共享内存，无需复制数据，支持高效的数据转换。\n",
    "3. 自动求导：\n",
    "- 张量支持自动微分，这对训练神经网络中的反向传播非常重要。\n",
    "4. API 易用性：\n",
    "- PyTorch 的张量 API 与 NumPy 的 ndarray API 非常相似，如果熟悉 NumPy，则使用张量会感觉非常自然。\n",
    "\n",
    "总结一句话：\n",
    "张量（Tensor）是**支持自动求导和 GPU 加速的多维数组**，它是 PyTorch 中的**核心数据结构**，用于表示**模型的输入、输出和参数**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d17aa0-9ff6-48df-a57e-43db612f7197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:33.052644Z",
     "iopub.status.busy": "2024-12-11T06:45:33.052158Z",
     "iopub.status.idle": "2024-12-11T06:45:35.940508Z",
     "shell.execute_reply": "2024-12-11T06:45:35.939285Z",
     "shell.execute_reply.started": "2024-12-11T06:45:33.052596Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5e5d3-6bbf-4659-b8c1-98b35dff672d",
   "metadata": {},
   "source": [
    "## Initializing a Tensor\n",
    "Tensor 可以通过很多种方式进行初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea0311-7be2-4e16-8280-70becd9c67ac",
   "metadata": {},
   "source": [
    "### 1. Directly from data\n",
    "由嵌套列表转换为 tensor，Pytorch 会自动推测数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd8d7b4-eaa7-4bfe-a004-527edc373fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:35.942398Z",
     "iopub.status.busy": "2024-12-11T06:45:35.941835Z",
     "iopub.status.idle": "2024-12-11T06:45:35.951495Z",
     "shell.execute_reply": "2024-12-11T06:45:35.950334Z",
     "shell.execute_reply.started": "2024-12-11T06:45:35.942355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "数据类型为:\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(f'x_data:\\n{x_data}\\n数据类型为:\\n{x_data.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe944a-ee85-480e-8ba2-309bdbad7bb7",
   "metadata": {},
   "source": [
    "### 2. From a Numpy array\n",
    "由 Numpy array 转换为 Tensor，它们之间是共享内存的，改变一个也会改变另外一个。\n",
    "\n",
    "可参考 [Bridge with Numpy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614b8558-4090-43e3-bf52-e724dec0d7a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:35.955291Z",
     "iopub.status.busy": "2024-12-11T06:45:35.954815Z",
     "iopub.status.idle": "2024-12-11T06:45:35.963871Z",
     "shell.execute_reply": "2024-12-11T06:45:35.962806Z",
     "shell.execute_reply.started": "2024-12-11T06:45:35.955249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "转换为 Tensor 后:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "改变后的 Numpy array:\n",
      "[[7 8]\n",
      " [3 4]]\n",
      "观察 x_np 是否也会随之改变:\n",
      "tensor([[7, 8],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f'Numpy array:\\n{np_array}\\n转换为 Tensor 后:\\n{x_np}')\n",
    "\n",
    "# 改变 np.array\n",
    "np_array[0] = [7,8]\n",
    "\n",
    "print(f'\\n改变后的 Numpy array:\\n{np_array}\\n观察 x_np 是否也会随之改变:\\n{x_np}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8a56-c8c6-4c0a-a4f6-c70bab6a7f91",
   "metadata": {},
   "source": [
    "### 3. From another tensor\n",
    "- [torch.ones](https://pytorch.org/docs/stable/generated/torch.ones.html#torch.ones) 好理解，张量中的值全都是 1\n",
    "- [torch.rand](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand) 生成的张量中的数值是在[0,1)区间内的随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624fcf0a-b9d8-4526-801a-37980cbee2f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:35.965452Z",
     "iopub.status.busy": "2024-12-11T06:45:35.965009Z",
     "iopub.status.idle": "2024-12-11T06:45:35.993943Z",
     "shell.execute_reply": "2024-12-11T06:45:35.992647Z",
     "shell.execute_reply.started": "2024-12-11T06:45:35.965411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全 1 Tensor: \n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "随机 Tensor: \n",
      "tensor([[0.6769, 0.2231],\n",
      "        [0.5869, 0.5095]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # 保留 x_data 的属性\n",
    "print(f'全 1 Tensor: \\n{x_ones}\\n')\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float) # 覆写 x_data 的数据类型\n",
    "print(f'随机 Tensor: \\n{x_rand}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ed057-6ffa-4997-ae45-2f2d4162cd32",
   "metadata": {},
   "source": [
    "### 4. With random or constant values\n",
    "`shape`要用元组的形式来表示 tensor 的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b39f6a-5238-4430-954e-edde2f079984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:35.995580Z",
     "iopub.status.busy": "2024-12-11T06:45:35.995121Z",
     "iopub.status.idle": "2024-12-11T06:45:36.007145Z",
     "shell.execute_reply": "2024-12-11T06:45:36.006054Z",
     "shell.execute_reply.started": "2024-12-11T06:45:35.995539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下生成形状为 (2, 3, 5) 的各类型 tensor！\n",
      "随机 tensor: \n",
      "tensor([[[0.5234, 0.8620, 0.1286, 0.2433, 0.0251],\n",
      "         [0.6767, 0.1613, 0.9619, 0.0538, 0.4775],\n",
      "         [0.2669, 0.1617, 0.1155, 0.6800, 0.6925]],\n",
      "\n",
      "        [[0.7333, 0.8868, 0.3315, 0.6481, 0.3191],\n",
      "         [0.1769, 0.1584, 0.5095, 0.7811, 0.8386],\n",
      "         [0.2861, 0.6514, 0.1578, 0.5741, 0.6747]]])\n",
      "\n",
      "全 1 tensor: \n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "\n",
      "全 0 tensor: \n",
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, 5)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'以下生成形状为 {shape} 的各类型 tensor！')\n",
    "print(f'随机 tensor: \\n{rand_tensor}\\n')\n",
    "print(f'全 1 tensor: \\n{ones_tensor}\\n')\n",
    "print(f'全 0 tensor: \\n{zeros_tensor}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff28609-9250-43b9-adef-67c07290eb1c",
   "metadata": {},
   "source": [
    "---\n",
    "## Attributes of a Tensor\n",
    "一个 tensor 拥有的特征:\n",
    "- shape 形状，即维度\n",
    "- dtype 数据类型\n",
    "- device 存储在什么硬件上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866102dd-bbe8-4402-9876-bb664157954a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.008728Z",
     "iopub.status.busy": "2024-12-11T06:45:36.008349Z",
     "iopub.status.idle": "2024-12-11T06:45:36.015797Z",
     "shell.execute_reply": "2024-12-11T06:45:36.014638Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.008688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor 的形状 torch.Size([3, 4])\n",
      "tensor 的数据类型 torch.float32\n",
      "tensor 的存储设备 cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "print(f'tensor 的形状 {tensor.shape}')\n",
    "print(f'tensor 的数据类型 {tensor.dtype}')\n",
    "print(f'tensor 的存储设备 {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6f25b-b862-4df3-b273-b804eeb0935d",
   "metadata": {},
   "source": [
    "---\n",
    "## Operations on Tensor\n",
    "PyTorch 支持丰富的张量操作，这些操作可以在GPU 上高效运行，但默认的张量是在 CPU 上创建的。要在 GPU 上操作张量，需要使用 .to(device) 方法将其移动到 GPU，但设备间的大量数据传输会消耗时间和内存，应尽量避免频繁切换设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84c6443-5697-49ca-8a85-d3bc79ab0241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.017390Z",
     "iopub.status.busy": "2024-12-11T06:45:36.016931Z",
     "iopub.status.idle": "2024-12-11T06:45:36.023726Z",
     "shell.execute_reply": "2024-12-11T06:45:36.022624Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.017349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "并没有可用的 gpu\n"
     ]
    }
   ],
   "source": [
    "# 如果存在 GPU 设备的话，可以将 tensor 转移到 gpu 上\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "else:\n",
    "    print('并没有可用的 gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acb210-b8af-406d-af35-911f0772db6c",
   "metadata": {},
   "source": [
    "### standard numpy-like indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed56f08-1a55-403e-8640-d010fda19b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.025351Z",
     "iopub.status.busy": "2024-12-11T06:45:36.024891Z",
     "iopub.status.idle": "2024-12-11T06:45:36.035540Z",
     "shell.execute_reply": "2024-12-11T06:45:36.034427Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.025310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "tensor([[0, 3, 0, 1],\n",
      "        [7, 2, 6, 2],\n",
      "        [8, 7, 7, 8],\n",
      "        [3, 7, 0, 7]])\n",
      "第一行: tensor([0, 3, 0, 1])\n",
      "第一列: tensor([0, 7, 8, 3])\n",
      "最后一列: tensor([1, 2, 8, 7])\n",
      "tensor([[0, 0, 0, 1],\n",
      "        [7, 0, 6, 2],\n",
      "        [8, 0, 7, 8],\n",
      "        [3, 0, 0, 7]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randint(0,10, (4,4))\n",
    "print(f'tensor:\\n{tensor}')\n",
    "print(f'第一行: {tensor[0]}')\n",
    "print(f'第一列: {tensor[:, 0]}')\n",
    "print(f'最后一列: {tensor[:, -1]}')\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5632ae-ecb3-4a6c-a09e-3ce47471768a",
   "metadata": {},
   "source": [
    "### Joining tensors\n",
    "连接 tensor \n",
    "如何理解参数 dim?\n",
    "dim = 1 可以理解为 在第二个维度上连接，结果是第二个维度的长度增加。在 2 维 tensor 中，就是按列连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73645842-445e-4481-a6e7-b84cadfb7004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.037143Z",
     "iopub.status.busy": "2024-12-11T06:45:36.036681Z",
     "iopub.status.idle": "2024-12-11T06:45:36.045914Z",
     "shell.execute_reply": "2024-12-11T06:45:36.044767Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.037102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
      "        [7, 0, 6, 2, 7, 0, 6, 2, 7, 0, 6, 2],\n",
      "        [8, 0, 7, 8, 8, 0, 7, 8, 8, 0, 7, 8],\n",
      "        [3, 0, 0, 7, 3, 0, 0, 7, 3, 0, 0, 7]])\n",
      "tensor([[0, 0, 0, 1],\n",
      "        [7, 0, 6, 2],\n",
      "        [8, 0, 7, 8],\n",
      "        [3, 0, 0, 7],\n",
      "        [0, 0, 0, 1],\n",
      "        [7, 0, 6, 2],\n",
      "        [8, 0, 7, 8],\n",
      "        [3, 0, 0, 7],\n",
      "        [0, 0, 0, 1],\n",
      "        [7, 0, 6, 2],\n",
      "        [8, 0, 7, 8],\n",
      "        [3, 0, 0, 7]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
    "print(t1)\n",
    "t2 = torch.cat([tensor, tensor, tensor], dim = 0)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2317a99-477b-41cd-9037-a769c85f114d",
   "metadata": {},
   "source": [
    "### Arithmetic operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16cabb4-7b4a-4305-bcca-49e8017895d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.047532Z",
     "iopub.status.busy": "2024-12-11T06:45:36.047074Z",
     "iopub.status.idle": "2024-12-11T06:45:36.058979Z",
     "shell.execute_reply": "2024-12-11T06:45:36.057796Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.047491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.]]) \n",
      "\n",
      " tensor([[7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.]]) \n",
      "\n",
      " tensor([[7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,2] = 2\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "print(y1, '\\n\\n', y2, '\\n\\n', y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e45737-3113-40fd-ba75-826d972f8969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.060586Z",
     "iopub.status.busy": "2024-12-11T06:45:36.060125Z",
     "iopub.status.idle": "2024-12-11T06:45:36.071178Z",
     "shell.execute_reply": "2024-12-11T06:45:36.069998Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.060545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.]]) \n",
      "\n",
      " tensor([[1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.]]) \n",
      "\n",
      " tensor([[1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.],\n",
      "        [1., 1., 4., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "print(z1, '\\n\\n', z2, '\\n\\n', z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ef9d7-ff9f-4d2f-9b1c-a4d14a4c43ad",
   "metadata": {},
   "source": [
    "### Single-element tensors\n",
    "如果有一个单元素的 tensor （通常是整合一个 tensor 中所有元素得来的），可以通过 `item()` 的方法将其转换为 python 的 `numerical value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a5ad2d-e5ad-4057-995b-ede7fa09bb40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.075406Z",
     "iopub.status.busy": "2024-12-11T06:45:36.074986Z",
     "iopub.status.idle": "2024-12-11T06:45:36.081755Z",
     "shell.execute_reply": "2024-12-11T06:45:36.080646Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.075365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805fa4c-ffc6-4af4-a017-484250f31518",
   "metadata": {},
   "source": [
    "### In-place operation\n",
    "在中文中，把这类操作叫做原地操作，在同一个内存地址上改变元素的值。这类操作都有一个`_`后缀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe366c13-fd56-4deb-b09b-5a85345bc283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T06:45:36.083368Z",
     "iopub.status.busy": "2024-12-11T06:45:36.082906Z",
     "iopub.status.idle": "2024-12-11T06:45:36.091575Z",
     "shell.execute_reply": "2024-12-11T06:45:36.090428Z",
     "shell.execute_reply.started": "2024-12-11T06:45:36.083327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 2., 1.],\n",
      "        [1., 1., 2., 1.],\n",
      "        [1., 1., 2., 1.],\n",
      "        [1., 1., 2., 1.]]) \n",
      "\n",
      "tensor([[6., 6., 7., 6.],\n",
      "        [6., 6., 7., 6.],\n",
      "        [6., 6., 7., 6.],\n",
      "        [6., 6., 7., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f'{tensor} \\n')\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
