{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84766534-72b5-46a8-a900-6d087e56b7fe",
   "metadata": {},
   "source": [
    "# Optimizing Model Parameter\n",
    "训练模型是一个迭代的过程，在每一次迭代中模型都会为输入数据生成对应的预测值，并且计算实际与预期之间的损失。随后会计算损失的导数，并且使用梯度下降的方法进行优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78df85c-233c-4e22-b72c-718b604ccb93",
   "metadata": {},
   "source": [
    "## Prerequisite Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcfc58a-4450-4115-86e4-399c1d426bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T02:38:25.424189Z",
     "iopub.status.busy": "2024-12-12T02:38:25.422275Z",
     "iopub.status.idle": "2024-12-12T02:38:29.771282Z",
     "shell.execute_reply": "2024-12-12T02:38:29.769214Z",
     "shell.execute_reply.started": "2024-12-12T02:38:25.424133Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root = '/work/Quickstart/data',\n",
    "    train = True,\n",
    "    download = False,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = '/work/Quickstart/data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c894be-5e9e-461d-bfab-4c2159daf0b5",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "超参数是用于控制模型优化过程的可调整的参数。\n",
    "\n",
    "不同的超参数会影响模型的训练以及收敛速度\n",
    "\n",
    "有几个超参数是经常关注的：\n",
    "- Number of Epoch：训练的迭代次数\n",
    "- Batch Size：在参数更新之前传递给网络的数据样本量\n",
    "- Learning rate：在每个批次或迭代时，需要在一个什么样的程度上去更新模型的参数。过小的值会导致学习缓慢，过大的值可能导致模型丧失学习能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939fbce3-9676-4629-a611-18a3b205cbe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T02:38:29.773752Z",
     "iopub.status.busy": "2024-12-12T02:38:29.773172Z",
     "iopub.status.idle": "2024-12-12T02:38:29.780834Z",
     "shell.execute_reply": "2024-12-12T02:38:29.779265Z",
     "shell.execute_reply.started": "2024-12-12T02:38:29.773708Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a24320-f499-48b5-b505-285170e7300c",
   "metadata": {},
   "source": [
    "## Optimization Loop\n",
    "每一次 epoch 都会训练一次模型，并进行优化。包含 2 个部分\n",
    "- 训练循环：迭代训练数据集，并尽可能的使优化参数收敛\n",
    "- 验证/测试循环：迭代测试数据集，观察模型的效果是否提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4077ea6-84b2-46f8-8dd1-7df299958caa",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "不同的损失函数，执行的任务不同\n",
    "\n",
    "- `nn.MSELoss`即 Mean Square Error, 均方误差，主要用于回归任务\n",
    "- `nn.NLLLoss`即 Negative Log Likelihood，负对数似然，主要用于分类任务\n",
    "- `nn.CrossEntropyLoss`即交叉熵损失，其结合了 `nn.LogSoftMax` 和 `nn.NLLLoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ddb5d7b-1eae-444a-b9a4-55f7fa55cb7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T02:38:29.784724Z",
     "iopub.status.busy": "2024-12-12T02:38:29.784269Z",
     "iopub.status.idle": "2024-12-12T02:38:29.791055Z",
     "shell.execute_reply": "2024-12-12T02:38:29.789454Z",
     "shell.execute_reply.started": "2024-12-12T02:38:29.784683Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ed5b9-a987-4cf4-9582-e9a8c5d0de47",
   "metadata": {},
   "source": [
    "## Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4dd81b3-ea79-4e5b-91b1-957c4fca9ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T02:38:29.792963Z",
     "iopub.status.busy": "2024-12-12T02:38:29.792487Z",
     "iopub.status.idle": "2024-12-12T02:38:29.800790Z",
     "shell.execute_reply": "2024-12-12T02:38:29.798859Z",
     "shell.execute_reply.started": "2024-12-12T02:38:29.792920Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4c2ea-bab9-478b-90c8-cc04dc7e684e",
   "metadata": {},
   "source": [
    "在训练循环内部，优化过程会发生在 3 个阶段\n",
    "- 调用`optimizer.zero_grad()`用来重置模型参数的梯度。由于梯度会自动叠加，因此在每一次迭代中都需要将梯度清零\n",
    "- 调用`loss.backward()`进行反向传播，存储参数的梯度\n",
    "- 调用`optimizer.step()`通过梯度来调整参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0fee68-08ec-4739-b295-315c74d06a9a",
   "metadata": {},
   "source": [
    "## Full implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194c6221-c8d9-42ae-aa69-6a7dd3269a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T02:38:29.803231Z",
     "iopub.status.busy": "2024-12-12T02:38:29.802650Z",
     "iopub.status.idle": "2024-12-12T02:38:29.821347Z",
     "shell.execute_reply": "2024-12-12T02:38:29.819543Z",
     "shell.execute_reply.started": "2024-12-12T02:38:29.803188Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset) # dataloader有几个attribute？\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d} / {size:>5d}]')\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0ee719-3e06-40dd-a919-7526b3896b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T02:38:29.823259Z",
     "iopub.status.busy": "2024-12-12T02:38:29.822849Z",
     "iopub.status.idle": "2024-12-12T02:41:38.245331Z",
     "shell.execute_reply": "2024-12-12T02:41:38.243469Z",
     "shell.execute_reply.started": "2024-12-12T02:38:29.823204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "loss: 2.297810 [   64 / 60000]\n",
      "loss: 2.290495 [ 6464 / 60000]\n",
      "loss: 2.274753 [12864 / 60000]\n",
      "loss: 2.271425 [19264 / 60000]\n",
      "loss: 2.243567 [25664 / 60000]\n",
      "loss: 2.213969 [32064 / 60000]\n",
      "loss: 2.223341 [38464 / 60000]\n",
      "loss: 2.180729 [44864 / 60000]\n",
      "loss: 2.180434 [51264 / 60000]\n",
      "loss: 2.151636 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 2.141100 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-----------------------\n",
      "loss: 2.141959 [   64 / 60000]\n",
      "loss: 2.138960 [ 6464 / 60000]\n",
      "loss: 2.076679 [12864 / 60000]\n",
      "loss: 2.103532 [19264 / 60000]\n",
      "loss: 2.044554 [25664 / 60000]\n",
      "loss: 1.981585 [32064 / 60000]\n",
      "loss: 2.019914 [38464 / 60000]\n",
      "loss: 1.921700 [44864 / 60000]\n",
      "loss: 1.926816 [51264 / 60000]\n",
      "loss: 1.873215 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 1.853471 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-----------------------\n",
      "loss: 1.876900 [   64 / 60000]\n",
      "loss: 1.853269 [ 6464 / 60000]\n",
      "loss: 1.723816 [12864 / 60000]\n",
      "loss: 1.782639 [19264 / 60000]\n",
      "loss: 1.674705 [25664 / 60000]\n",
      "loss: 1.622387 [32064 / 60000]\n",
      "loss: 1.663059 [38464 / 60000]\n",
      "loss: 1.542668 [44864 / 60000]\n",
      "loss: 1.573107 [51264 / 60000]\n",
      "loss: 1.486202 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.484594 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-----------------------\n",
      "loss: 1.543926 [   64 / 60000]\n",
      "loss: 1.514117 [ 6464 / 60000]\n",
      "loss: 1.357133 [12864 / 60000]\n",
      "loss: 1.446779 [19264 / 60000]\n",
      "loss: 1.333108 [25664 / 60000]\n",
      "loss: 1.322888 [32064 / 60000]\n",
      "loss: 1.354472 [38464 / 60000]\n",
      "loss: 1.261763 [44864 / 60000]\n",
      "loss: 1.301853 [51264 / 60000]\n",
      "loss: 1.215893 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.228254 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-----------------------\n",
      "loss: 1.296508 [   64 / 60000]\n",
      "loss: 1.281364 [ 6464 / 60000]\n",
      "loss: 1.116777 [12864 / 60000]\n",
      "loss: 1.232515 [19264 / 60000]\n",
      "loss: 1.115104 [25664 / 60000]\n",
      "loss: 1.134119 [32064 / 60000]\n",
      "loss: 1.169844 [38464 / 60000]\n",
      "loss: 1.092095 [44864 / 60000]\n",
      "loss: 1.134933 [51264 / 60000]\n",
      "loss: 1.062020 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.071119 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-----------------------\n",
      "loss: 1.133972 [   64 / 60000]\n",
      "loss: 1.136564 [ 6464 / 60000]\n",
      "loss: 0.958849 [12864 / 60000]\n",
      "loss: 1.098188 [19264 / 60000]\n",
      "loss: 0.979761 [25664 / 60000]\n",
      "loss: 1.006876 [32064 / 60000]\n",
      "loss: 1.056103 [38464 / 60000]\n",
      "loss: 0.985256 [44864 / 60000]\n",
      "loss: 1.026564 [51264 / 60000]\n",
      "loss: 0.964995 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.969354 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-----------------------\n",
      "loss: 1.020761 [   64 / 60000]\n",
      "loss: 1.042554 [ 6464 / 60000]\n",
      "loss: 0.849993 [12864 / 60000]\n",
      "loss: 1.008333 [19264 / 60000]\n",
      "loss: 0.893035 [25664 / 60000]\n",
      "loss: 0.916825 [32064 / 60000]\n",
      "loss: 0.981125 [38464 / 60000]\n",
      "loss: 0.916409 [44864 / 60000]\n",
      "loss: 0.951784 [51264 / 60000]\n",
      "loss: 0.899738 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.899787 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-----------------------\n",
      "loss: 0.937245 [   64 / 60000]\n",
      "loss: 0.977257 [ 6464 / 60000]\n",
      "loss: 0.771789 [12864 / 60000]\n",
      "loss: 0.944794 [19264 / 60000]\n",
      "loss: 0.834562 [25664 / 60000]\n",
      "loss: 0.851006 [32064 / 60000]\n",
      "loss: 0.928051 [38464 / 60000]\n",
      "loss: 0.870684 [44864 / 60000]\n",
      "loss: 0.898193 [51264 / 60000]\n",
      "loss: 0.852989 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.849637 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-----------------------\n",
      "loss: 0.872925 [   64 / 60000]\n",
      "loss: 0.928352 [ 6464 / 60000]\n",
      "loss: 0.713078 [12864 / 60000]\n",
      "loss: 0.897385 [19264 / 60000]\n",
      "loss: 0.792424 [25664 / 60000]\n",
      "loss: 0.801530 [32064 / 60000]\n",
      "loss: 0.887751 [38464 / 60000]\n",
      "loss: 0.838822 [44864 / 60000]\n",
      "loss: 0.858092 [51264 / 60000]\n",
      "loss: 0.817434 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.811597 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-----------------------\n",
      "loss: 0.821460 [   64 / 60000]\n",
      "loss: 0.889229 [ 6464 / 60000]\n",
      "loss: 0.667192 [12864 / 60000]\n",
      "loss: 0.860896 [19264 / 60000]\n",
      "loss: 0.760334 [25664 / 60000]\n",
      "loss: 0.763430 [32064 / 60000]\n",
      "loss: 0.855132 [38464 / 60000]\n",
      "loss: 0.815226 [44864 / 60000]\n",
      "loss: 0.827028 [51264 / 60000]\n",
      "loss: 0.788789 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.781290 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-----------------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
